{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Predictor - LSTM \n",
    "\n",
    "![deep-learning.jpg](Images/deep-learning.jpg)\n",
    "\n",
    "Due to the volatility of cryptocurrency speculation, investors will often try to incorporate sentiment from social media and news articles to help guide their trading strategies. One such indicator is the [Crypto Fear and Greed Index (FNG)](https://alternative.me/crypto/fear-and-greed-index/) which attempts to use a variety of data sources to produce a daily FNG value for cryptocurrency. You have been asked to help build and evaluate deep learning models using both the FNG values and simple closing prices to determine if the FNG indicator provides a better signal for cryptocurrencies than the normal closing price data.\n",
    "\n",
    "In this assignment, you will use deep learning recurrent neural networks to model bitcoin closing prices. One model will use the FNG indicators to predict the closing price while the second model will use a window of closing prices to predict the nth closing price.\n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. [Prepare the data for training and testing](#prepare-the-data-for-training-and-testing)\n",
    "2. [Build and train custom LSTM RNNs](#build-and-train-custom-lstm-rnns)\n",
    "3. [Evaluate the performance of each model](#evaluate-the-performance-of-each-model)\n",
    "\n",
    "- - -\n",
    "\n",
    "### Files\n",
    "\n",
    "[Closing Prices Starter Notebook](Starter_Code/lstm_stock_predictor_closing.ipynb)\n",
    "\n",
    "[FNG Starter Notebook](Starter_Code/lstm_stock_predictor_fng.ipynb)\n",
    "\n",
    "- - -\n",
    "\n",
    "## Instructions\n",
    "\n",
    "### Prepare the data for training and testing\n",
    "\n",
    "Use the starter code as a guide to create a Jupyter Notebook for each RNN. The starter code contains a function to help window the data for each dataset.\n",
    "\n",
    "For the Fear and Greed model, you will use the FNG values to try and predict the closing price. A function is provided in the notebook to help with this.\n",
    "\n",
    "For the closing price model, you will use previous closing prices to try and predict the next closing price. A function is provided in the notebook to help with this.\n",
    "\n",
    "Each model will need to use 70% of the data for training and 30% of the data for testing.\n",
    "\n",
    "Apply a MinMaxScaler to the X and y values to scale the data for the model.\n",
    "\n",
    "Finally, reshape the X_train and X_test values to fit the model's requirement of (samples, time steps, features).\n",
    "\n",
    "### Build and train custom LSTM RNNs\n",
    "\n",
    "In each Jupyter Notebook, create the same custom LSTM RNN architecture. In one notebook, you will fit the data using the FNG values. In the second notebook, you will fit the data using only closing prices.\n",
    "\n",
    "Use the same parameters and training steps for each model. This is necessary to compare each model accurately.\n",
    "\n",
    "### Evaluate the performance of each model\n",
    "\n",
    "Finally, use the testing data to evaluate each model and compare the performance.\n",
    "\n",
    "Use the above to answer the following:\n",
    "\n",
    "> Which model has a lower loss?\n",
    ">\n",
    "> Which model tracks the actual values better over time?\n",
    ">\n",
    "> Which window size works best for the model?\n",
    "\n",
    "- - -\n",
    "\n",
    "### Resources\n",
    "\n",
    "[Keras Sequential Model Guide](https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n",
    "[Illustrated Guide to LSTMs](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
    "\n",
    "[Stanford's RNN Cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n",
    "\n",
    "- - -\n",
    "\n",
    "### Hints and Considerations\n",
    "\n",
    "Experiment with the model architecture and parameters to see which provides the best results, but be sure to use the same architecture and parameters when comparing each model.\n",
    "\n",
    "For training, use at least 10 estimators for both models.\n",
    "\n",
    "- - -\n",
    "\n",
    "### Submission\n",
    "\n",
    "* Create Jupyter Notebooks for the homework and host the notebooks on GitHub.\n",
    "\n",
    "* Include a Markdown that summarizes your homework and include this report in your GitHub repository.\n",
    "\n",
    "* Submit the link to your GitHub project to Bootcamp Spot.\n",
    "\n",
    "- - -\n",
    "\n",
    "Â© 2019 Trilogy Education Services, a 2U, Inc. brand. All Rights Reserved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Predictor - Long Short Term Memory Networks\n",
    "\n",
    "![deep-learning.jpg](Images/deep-learning.jpg)\n",
    "\n",
    "Due to the volatility of cryptocurrency speculation, investors often try to incorporate sentiment from social media and news articles to guide their trading strategies. [Cyrpto Fear & Greed Index(FNG)](https://alternative.me/crypto/fear-and-greed-index/) is an indicator that attempts to use variety of data sources to produce a daily FNG value for cryptocurrency. \n",
    "\n",
    "Using deep learning recurrent neural networks, build and evaluate bitcoin closing prices to determine if the FNG indicator provides better signal for cryptocurrencies than the normal closing price data. One model will use the FNG indicators to provide the closing prices while the second model will use a window of closing prices to predict the nth closing price.\n",
    "\n",
    "- - -\n",
    "\n",
    "### Files\n",
    "\n",
    "[Closing Prices Starter Notebook](Starter_Code/lstm_stock_predictor_closing.ipynb)\n",
    "\n",
    "[FNG Starter Notebook](Starter_Code/lstm_stock_predictor_fng.ipynb)\n",
    "\n",
    "- - -\n",
    "<details>\n",
    "<summary>Prepare the data for training and testing</summary>\n",
    "    \n",
    "<br>1. Use of Starter code as a guide to create a Jupyter Notebook for each RNN that contains a function to help window the data for each dataset.</br>\n",
    "    \n",
    "    \n",
    "    ```python\n",
    "        # This function accepts the column number for the features (X) and the target (y). It chunks the data up with a rolling window of Xt-n to predict Xt. It returns a numpy array of X any y\n",
    "    \n",
    "        def window_data(df, window, feature_col_number, target_col_number):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(len(df) - window - 1):\n",
    "            features = df.iloc[i:(i + window), feature_col_number]\n",
    "            target = df.iloc[(i + window), target_col_number]\n",
    "            X.append(features)\n",
    "            y.append(target)\n",
    "        return np.array(X), np.array(y).reshape(-1, 1)\n",
    "    ```\n",
    "    \n",
    "   <br>2. For Fear & Greed Model, use FNG values to try and predict the closing price while for closing price model, use the previous closing prices to predict the next closing prices.</br>\n",
    "   \n",
    "   \n",
    "   ```python\n",
    "        # Predict Closing Prices using a 10 day window of previous closing prices. Try a window size anywhere from 1 to 10 and see how the model performance changes\n",
    "        window_size = 1\n",
    "\n",
    "        # Column index 1 is the `Close` column & Column index 0 is the 'FNG'\n",
    "        feature_column = 1\n",
    "        target_column = 1\n",
    "        X, y = window_data(df, window_size, feature_column, target_column)\n",
    "   ```\n",
    "    \n",
    "\n",
    "<br>3. Each model will need to use 70% of the data for training and 30% of the data for testing.</br>\n",
    "   \n",
    "   ```python\n",
    "        split = int(0.7 * len(X))\n",
    "        X_train = X[: split - 1]\n",
    "        X_test = X[split:]\n",
    "        y_train = y[: split - 1]\n",
    "        y_test = y[split:]\n",
    "   ```\n",
    "    \n",
    "<br>4. Apply a MinMaxScaler to the X and y values to scale the data for the model.</br>\n",
    "   \n",
    "   ```python\n",
    "        # Use MinMaxScaler to scale the data between 0 and 1. Importing the MinMaxScaler from sklearn\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        # Create a MinMaxScaler object\n",
    "        scaler = MinMaxScaler()\n",
    "        # Fit the MinMaxScaler object with the features data X\n",
    "        scaler.fit(X)\n",
    "        # Scale the features training and testing sets\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # Fit the MinMaxScaler object with the target data Y\n",
    "        scaler.fit(y)\n",
    "        # Scale the target training and testing sets\n",
    "        y_train = scaler.transform(y_train)\n",
    "        y_test = scaler.transform(y_test)\n",
    "   ```\n",
    "\n",
    "<br>5. Finally, reshape the X_train and X_test values to fit the model's requirement of (samples, time steps, features).</br>\n",
    "   \n",
    "   ```python\n",
    "        # Reshape the features for the model\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "   ```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "\n",
    "\n",
    "<summary>Build and train custom LSTM RNNs</summary>\n",
    "    \n",
    "<br>1. Import the required library from tensorflow</br>\n",
    "    \n",
    "    ```python\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    ```\n",
    "    \n",
    "<br>2. Define the model architecture</br>\n",
    "   \n",
    "   ```python\n",
    "        # Build the LSTM model. \n",
    "   \n",
    "        model = Sequential()\n",
    "\n",
    "        number_units = 30\n",
    "        dropout_fraction = 0.2\n",
    "        # The return sequences need to be set to True if you are adding additional LSTM layers, but don't have to do this for the final layer. \n",
    "        # Layer 1\n",
    "        model.add(LSTM(\n",
    "            units=number_units,\n",
    "            return_sequences=True,\n",
    "            input_shape=(X_train.shape[1], 1))\n",
    "            )\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Layer 2\n",
    "        model.add(LSTM(units=number_units, return_sequences=True))\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Layer 3\n",
    "        model.add(LSTM(units=number_units))\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Output layer\n",
    "        model.add(Dense(1))\n",
    "   ```\n",
    "    \n",
    "<br>3. Compile the model</br>\n",
    "   \n",
    "   ```python\n",
    "       model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "   ```\n",
    "<br>4. Summarize the model</br>\n",
    "   \n",
    "   ![lstm_model_summary.png](Images/lstm_model_summary.png)\n",
    "   \n",
    "   <br>5. Fit the model and train the data</br>\n",
    "   \n",
    "   ```python\n",
    "        # Train the model\n",
    "        # Use at least 10 epochs\n",
    "        # Do not shuffle the data\n",
    "        # Experiement with the batch size, but a smaller batch size is recommended\n",
    "        model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=5, verbose=1)\n",
    "   ```  \n",
    "    \n",
    " | Closing Price                       | FNG                              |\n",
    " | ----------------------------------- | ----------------------------------- |\n",
    " | <img src=\"Images/closing_price_model.png\" width=\"400\" />  | <img src=\"Images/fng_model.png\" width=\"400\" />  |\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Evaluate the performance of each model</summary>\n",
    "    \n",
    "<br>1. Evaluate the model using the `X_test` and `y_test` data</br>\n",
    "\n",
    "| **Closing Price**              | **FNG**                        |\n",
    "| :--------------------------: | :-------------------------- |\n",
    "| Loss = 0.0060              | FNG Loss : 0.07320         |\n",
    "\n",
    "* Closing Price model has a lower loss\n",
    "\n",
    "<br>2. Use `X_test` data to make the predictions</br>\n",
    "\n",
    "<br>3. Recover the original prices instead of the scaled version</br>\n",
    "\n",
    "    ```python\n",
    "        predicted_prices = scaler.inverse_transform(predicted)\n",
    "        real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    ```\n",
    "<br>4. Create a DataFrame of Real (X) vs. Predicted Values</br>\n",
    "\n",
    "| **Closing Price**                       | **FNG**                              |\n",
    "| ----------------------------------- | ----------------------------------- |\n",
    "| <img src=\"Images/closing_price_results.png\" width=\"400\" />  | <img src=\"Images/fng_results.png\" width=\"400\" />  |\n",
    "\n",
    "* Closing Prices model tracks the actual values better over time.\n",
    "\n",
    "<br>5. Plot the Real vs. Predicted values on a Line chart\n",
    " \n",
    "| **Closing Price**                       | **FNG**                              |\n",
    "| ----------------------------------- | ----------------------------------- |\n",
    "| <img src=\"Images/closing_price_graph.png\" width=\"500\" />  | <img src=\"Images/fng_plot.png\" width=\"500\" />  |\n",
    "\n",
    "\n",
    "* Window size 7 works best for the model.\n",
    "\n",
    "</details>\n",
    "\n",
    "- - -\n",
    "\n",
    "### Resources\n",
    "\n",
    "[Keras Sequential Model Guide](https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n",
    "[Illustrated Guide to LSTMs](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
    "\n",
    "[Stanford's RNN Cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n",
    "\n",
    "- - -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
